{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "%pip install matplotlib\n",
    "%pip install SpeechRecognition\n",
    "%pip install wave\n",
    "%pip install librosa\n",
    "%pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "# import subprocess\n",
    "\n",
    "# # # # convert to wav file\n",
    "# subprocess.call(['ffmpeg', '-i', 'moli_assovio_2.ogg',\n",
    "#                   'moli_assovio_2.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "rate, data = wav.read('../dido.wav')\n",
    "\n",
    "# somando os dois canais e normalizando (passando de estereo para mono)\n",
    "# data = np.sum(data, axis=1) / 2 \n",
    "# plt.plot(data)\n",
    "# plt.xlabel('Qtd. Amostras')\n",
    "# plt.ylabel('Amplitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrar o comprimento (total de amostras)\n",
    "n = len(data)\n",
    "\n",
    "# Frequencia de amostragem por sinal (quantas amostras por segundo)\n",
    "fs = 48000 #48khz (audio) ou 44100 44.1khz (padrao spotify apple music) \n",
    "# https://emastered.com/pt/blog/sample-rate-for-audio#:~:text=A%20melhor%20taxa%20de%20amostragem,da%20sua%20onda%20sonora%20original.\n",
    "\n",
    "\n",
    "T = 1/fs # tempo entre uma amostra e outra (inverso entre uma amostra e outra)\n",
    "\n",
    "t = np.arange(0,n/fs,T) # (vetor de tempo) começa em 0seg, vai até o valor final do comprimento / frequencia de amostragem, e vai andando de T em T (valor calculado na variavel T)\n",
    "\n",
    "# plt.plot(t, data)\n",
    "# plt.xlabel('Tempo (s)')\n",
    "# plt.ylabel('Amplitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# saindo de segundos e indo para hz\n",
    "f = fftfreq(n,T)\n",
    "\n",
    "# numero complexo (transformada)\n",
    "transf = fft(data)\n",
    "\n",
    "# módulo - para tirar os números complexos (módulo)\n",
    "transf = np.abs(transf)\n",
    "\n",
    "# plt.plot(f[f > 0],transf[f > 0]*1/n) # mascara para pegar apenas os sinais com frequencias maiores que zeros e normalização o eixo vertical (dividir a transformada pelo tamanho do sinal)\n",
    "# plt.xlabel('Frequência (Hz)')\n",
    "# plt.ylabel('Amplitute')\n",
    "\n",
    "\n",
    "# plt.ylim([0, 50])\n",
    "# plt.xlim([0, 30])\n",
    "# len(transf[f > 0]*1/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m df_hashes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../assovio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m Audio(y, rate\u001b[38;5;241m=\u001b[39m sr)\n\u001b[0;32m     15\u001b[0m S \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mstft(y, n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, win_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:83\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     81\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m---> 83\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:82\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     81\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:1158\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msign(x0) \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(x1)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;129;43m@guvectorize\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(float32[:], float32, bool_, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(float64[:], float64, bool_, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(n),(),()->(n)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnopython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m_zc_wrapper\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pragma: no cover\u001b[39;49;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Vectorized wrapper for zero crossing stencil\"\"\"\u001b[39;49;00m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_zc_stencil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_pos\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\decorators.py:203\u001b[0m, in \u001b[0;36mguvectorize.<locals>.wrap\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    201\u001b[0m guvec \u001b[38;5;241m=\u001b[39m GUVectorize(func, signature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fty \u001b[38;5;129;01min\u001b[39;00m ftylist:\n\u001b[1;32m--> 203\u001b[0m     \u001b[43mguvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ftylist) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    205\u001b[0m     guvec\u001b[38;5;241m.\u001b[39mdisable_compile()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:137\u001b[0m, in \u001b[0;36mGUFunc.add\u001b[1;34m(self, fty)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, fty):\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgufunc_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:257\u001b[0m, in \u001b[0;36m_BaseUFuncBuilder.add\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     targetoptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_func\u001b[38;5;241m.\u001b[39mtargetoptions\n\u001b[1;32m--> 257\u001b[0m cres, args, return_type \u001b[38;5;241m=\u001b[39m \u001b[43m_compile_element_wise_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetoptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_signature(cres, args, return_type)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigs\u001b[38;5;241m.\u001b[39mappend(sig)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:175\u001b[0m, in \u001b[0;36m_compile_element_wise_function\u001b[1;34m(nb_func, targetoptions, sig)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_element_wise_function\u001b[39m(nb_func, targetoptions, sig):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Do compilation\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Return CompileResult to test\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     cres \u001b[38;5;241m=\u001b[39m \u001b[43mnb_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargetoptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     args, return_type \u001b[38;5;241m=\u001b[39m sigutils\u001b[38;5;241m.\u001b[39mnormalize_signature(sig)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cres, args, return_type\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:123\u001b[0m, in \u001b[0;36mUFuncDispatcher.compile\u001b[1;34m(self, sig, locals, **targetoptions)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Disable loop lifting\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# The feature requires a real\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m#  python function\u001b[39;00m\n\u001b[0;32m    121\u001b[0m flags\u001b[38;5;241m.\u001b[39menable_looplift \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:150\u001b[0m, in \u001b[0;36mUFuncDispatcher._compile_core\u001b[1;34m(self, sig, flags, locals)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m targetconfig\u001b[38;5;241m.\u001b[39mConfigStack()\u001b[38;5;241m.\u001b[39menter(flags\u001b[38;5;241m.\u001b[39mcopy()):\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m store_overloads_on_success():\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;66;03m# attempt look up of existing\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m         cres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_overload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cres \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m cres\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\caching.py:633\u001b[0m, in \u001b[0;36mCache.load_overload\u001b[1;34m(self, sig, target_context)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03mLoad and recreate the cached object for the given signature,\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03musing the *target_context*.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# Refresh the context to ensure it is initialized\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m \u001b[43mtarget_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guard_against_spurious_io_errors():\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_overload(sig, target_context)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\base.py:267\u001b[0m, in \u001b[0;36mBaseContext.refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03mRefresh context with new declarations from known registries.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03mUseful for third-party extensions.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# load target specific registries\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_additional_registries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Populate the builtin registry, this has to happen after loading\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# additional registries as some of the \"additional\" registries write\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# their implementations into the builtin_registry and would be missed if\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# this ran first.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(builtin_registry)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\cpu.py:99\u001b[0m, in \u001b[0;36mCPUContext.load_additional_registries\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(jitclassimpl\u001b[38;5;241m.\u001b[39mclass_impl_registry)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# load 3rd party extensions\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mnumba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mentrypoints\u001b[38;5;241m.\u001b[39minit_all()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# fix for #8940\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndarray\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../assovio.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../joao_assovio.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste2 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../dido.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste_dido = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../moli_assovio_2.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste3 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../ratos.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste4 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('../ratos_cover.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste5 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "# print(len(df_concat))\n",
    "\n",
    "# ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "# ax1.set_title('Relação entre Frequência e Tempo')\n",
    "# ax1.set_ylabel('Hz')\n",
    "# ax1.set_xlabel('Tempo')\n",
    "# ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['target'] = 0\n",
    "\n",
    "teste2['target'] = 1\n",
    "\n",
    "teste3['target'] = 2\n",
    "\n",
    "teste4['target'] = 3\n",
    "\n",
    "teste5['target'] = 4\n",
    "\n",
    "teste_dido['target'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.concat([teste, teste2, teste3, teste4, teste5, teste_dido], ignore_index = True)\n",
    "target = test_final.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import joblib \n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_final\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = X_train / 255\n",
    "X_test_n = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) \n",
    "X_train_pca = pca.fit_transform(X_train_n)\n",
    "X_test_pca = pca.transform(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"dados de treino: {X_train.shape}\")\n",
    "# print(f\"dados de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(2, 15))\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_pca, y_train_int)\n",
    "    \n",
    "    y_test_int_pred = knn.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test_int, y_test_int_pred)\n",
    "    metrics.append({\n",
    "        'k': k,\n",
    "        'accuracy': test_accuracy,\n",
    "        'classification_report': classification_report(y_test_int, y_test_int_pred, output_dict=True),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = None\n",
    "\n",
    "for metric in metrics:\n",
    "    if best_metric is None or metric['accuracy'] > best_metric['accuracy']:\n",
    "        best_metric = metric\n",
    "\n",
    "\n",
    "if best_metric:\n",
    "    print(f'Best K = {best_metric[\"k\"]}')\n",
    "    k_best = best_metric[\"k\"]\n",
    "    print(f'Best Test Accuracy: {best_metric[\"accuracy\"] * 100:.2f}%')\n",
    "    print('Best Classification Report:')\n",
    "    print(classification_report(y_test_int, knn.predict(X_test_pca)))\n",
    "conf_matrix = confusion_matrix(y_test_int, y_test_int_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.title(f'Confusion Matrix for K={k_best}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors=k_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(scaler, knn_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=k_best)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models:\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    end_time = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    recall = classification_rep['weighted avg']['recall']\n",
    "    f1_score = classification_rep['weighted avg']['f1-score']\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia %': round(accuracy * 100, 2),\n",
    "        'Recall %': round(recall * 100, 2),\n",
    "        'F1-score %': round(f1_score * 100, 2),\n",
    "        'Tempo de Execução (s)': round(runtime, 2)\n",
    "    })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df = pd.DataFrame(results)\n",
    "\n",
    "print(resultados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont0 = 0\n",
    "# cont1 = 0\n",
    "# cont2 = 0\n",
    "# cont3 = 0\n",
    "# cont4 = 0\n",
    "# cont5 = 0\n",
    "\n",
    "# for i in range(len(teste)):\n",
    "#     if teste[i] == 5:\n",
    "#         cont5 +=1\n",
    "#     elif teste[i] == 4:\n",
    "#         cont4 += 1       \n",
    "#     elif teste[i] == 3:\n",
    "#         cont3 += 1\n",
    "#     elif teste[i] == 2:\n",
    "#         cont2 += 1\n",
    "#     elif teste[i] == 1:\n",
    "#         cont1 += 1\n",
    "#     elif teste[i] == 0:\n",
    "#         cont0 += 1\n",
    "\n",
    "# print(f'Frequências similares a 0: {cont0}')\n",
    "# print(f'Frequências similares a 1: {cont1}')\n",
    "# print(f'Frequências similares a 2: {cont2}')\n",
    "# print(f'Frequências similares a 3: {cont3}')\n",
    "# print(f'Frequências similares a 4: {cont4}')\n",
    "# print(f'Frequências similares a 5: {cont5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly', 'Dido']\n",
    "# frequencies = [cont0, cont1, cont2, cont3, cont4, cont5]\n",
    "\n",
    "# plt.bar(labels, frequencies, color='blue')\n",
    "# plt.xlabel('Valores')\n",
    "# plt.ylabel('Frequência')\n",
    "# plt.title('Frequência dos Valores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'model_v-28_08.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib = joblib.load('model_v-28_08.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
