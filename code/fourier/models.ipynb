{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "%pip install matplotlib\n",
    "%pip install SpeechRecognition\n",
    "%pip install wave\n",
    "%pip install librosa\n",
    "%pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "# import subprocess\n",
    "\n",
    "# # # # convert to wav file\n",
    "# subprocess.call(['ffmpeg', '-i', 'moli_assovio_2.ogg',\n",
    "#                   'moli_assovio_2.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "rate, data = wav.read('dido.wav')\n",
    "\n",
    "# somando os dois canais e normalizando (passando de estereo para mono)\n",
    "# data = np.sum(data, axis=1) / 2 \n",
    "plt.plot(data)\n",
    "plt.xlabel('Qtd. Amostras')\n",
    "plt.ylabel('Amplitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrar o comprimento (total de amostras)\n",
    "n = len(data)\n",
    "\n",
    "# Frequencia de amostragem por sinal (quantas amostras por segundo)\n",
    "fs = 48000 #48khz (audio) ou 44100 44.1khz (padrao spotify apple music) \n",
    "# https://emastered.com/pt/blog/sample-rate-for-audio#:~:text=A%20melhor%20taxa%20de%20amostragem,da%20sua%20onda%20sonora%20original.\n",
    "\n",
    "\n",
    "T = 1/fs # tempo entre uma amostra e outra (inverso entre uma amostra e outra)\n",
    "\n",
    "t = np.arange(0,n/fs,T) # (vetor de tempo) começa em 0seg, vai até o valor final do comprimento / frequencia de amostragem, e vai andando de T em T (valor calculado na variavel T)\n",
    "\n",
    "plt.plot(t, data)\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Amplitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# saindo de segundos e indo para hz\n",
    "f = fftfreq(n,T)\n",
    "\n",
    "# numero complexo (transformada)\n",
    "transf = fft(data)\n",
    "\n",
    "# módulo - para tirar os números complexos (módulo)\n",
    "transf = np.abs(transf)\n",
    "\n",
    "plt.plot(f[f > 0],transf[f > 0]*1/n) # mascara para pegar apenas os sinais com frequencias maiores que zeros e normalização o eixo vertical (dividir a transformada pelo tamanho do sinal)\n",
    "plt.xlabel('Frequência (Hz)')\n",
    "plt.ylabel('Amplitute')\n",
    "\n",
    "\n",
    "# plt.ylim([0, 50])\n",
    "# plt.xlim([0, 30])\n",
    "len(transf[f > 0]*1/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_transf = pd.DataFrame(transf[f > 0]*1/n)\n",
    "# df_transf.columns = ['Amplitude']\n",
    "# df_valores = pd.DataFrame()\n",
    "\n",
    "# cont = 0\n",
    "# hashtags = []\n",
    "# f_hashtag = ''\n",
    "\n",
    "# for i in range(0, int(df_transf['Amplitude'].max()) + 100, 10) :\n",
    "#    cont = 0\n",
    "#    for j in df_transf['Amplitude']:\n",
    "#       if j > i :  \n",
    "#          cont+=1\n",
    "#    # print(f'Número de valores de Amplitude maiores que {i} e menores que {i+100}: {cont}')\n",
    "#    if (cont > 0):\n",
    "#       hashtag = f\"{i}{i+100}{cont}\"\n",
    "#       hashtags.append(hashtag)\n",
    "   \n",
    "# f_hashtag = ' '.join(hashtags)\n",
    "\n",
    "# print(f'Hashtag para essa música: {f_hashtag}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunksize = 1024 # tamanho que o array será dividido (cada chunk tem esse tamanho) 1024 elementos\n",
    "# chunks = int(len(transf) / chunksize)\n",
    "# result = []\n",
    "\n",
    "# for j in range(chunks):\n",
    "#     arraychunk = np.zeros(chunksize) # criação de novo array preenchido com zero\n",
    "#     for i in range(chunksize):\n",
    "#         arraychunk[i] = transf[(j * chunksize) + i] # mapeando a porção do array transf correspondente ao pedaço j no arraychunk\n",
    "#     result.append(arraychunk)\n",
    "# print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges = np.arange(40, 301, 10)  # Intervalos de 10 em 10 Hz\n",
    "# fuzfactor = 1  # Fator de ajuste menor para mais precisão\n",
    "\n",
    "# # Inicialização dos highscores e points para os intervalos de interesse\n",
    "# highscores = [0] * len(ranges)\n",
    "# points = [0] * len(ranges)\n",
    "\n",
    "# # Processamento da transformada completa\n",
    "# for freq in range(40, 301):\n",
    "#     if transf[freq] > 0:\n",
    "#         mag = np.log(np.abs(transf[freq]) + 1)\n",
    "#         i = 0\n",
    "#         while i < len(ranges) and ranges[i] < freq:\n",
    "#             i += 1\n",
    "#         if i < len(ranges) and mag > highscores[i]:\n",
    "#             highscores[i] = mag\n",
    "#             points[i] = freq\n",
    "\n",
    "# # Cálculo da hashtag única com mais detalhes\n",
    "# h = 0\n",
    "# for i in range(len(points)):\n",
    "#     h += (points[i] - (points[i] % fuzfactor)) * (10 ** (len(points) - i - 1))\n",
    "\n",
    "# print(f\"Hashtag: {h}\")\n",
    "\n",
    "# # Extraindo os pontos individuais para leitura\n",
    "# h_copy = h\n",
    "# extracted_points = []\n",
    "\n",
    "# for i in range(len(points)):\n",
    "#     factor = 10 ** (len(points) - i - 1)\n",
    "#     point = (h_copy // factor) * fuzfactor\n",
    "#     extracted_points.append(point)\n",
    "#     h_copy %= factor\n",
    "\n",
    "# print(f\"Frequencias: {extracted_points}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('assovio.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('joao_assovio.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste2 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('dido.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste_dido = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('moli_assovio_2.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste3 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('ratos.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste4 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes_freq1 = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('ratos_cover.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes_freq1.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste5 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes_freq1, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "freq_1 = frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['target'] = 0\n",
    "# teste['artist'] = 'Dido - Cover 1'\n",
    "# teste['music'] = 'Thank You'\n",
    "\n",
    "teste2['target'] = 1\n",
    "# teste2['artist'] = 'Dido'\n",
    "# teste2['music'] = 'Thank You'\n",
    "\n",
    "teste3['target'] = 2\n",
    "# teste3['artist'] = 'Dido - Cover 2'\n",
    "# teste3['music'] = 'Thank You'\n",
    "\n",
    "teste4['target'] = 3\n",
    "# teste4['artist'] = 'Ratos de Porão'\n",
    "# teste4['music'] = 'Caos'\n",
    "\n",
    "teste5['target'] = 4\n",
    "# teste5['artist'] = 'Soulfly'\n",
    "# teste5['music'] = 'Caos'\n",
    "\n",
    "teste_dido['target'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.concat([teste, teste2, teste3, teste4, teste5, teste_dido], ignore_index = True)\n",
    "target = test_final.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import joblib \n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_final\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "# X_test_scaled = scaler.transform(X_test.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = ['artist', 'music']\n",
    "# numerical_cols = ['Frequencia', 'Tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numerical_cols),\n",
    "#         ('cat', OneHotEncoder(), categorical_cols)\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "# X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_n = X_train_transformed / 255\n",
    "# X_test_n = X_test_transformed / 255\n",
    "\n",
    "X_train_n = X_train / 255\n",
    "X_test_n = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) \n",
    "X_train_pca = pca.fit_transform(X_train_n)\n",
    "X_test_pca = pca.transform(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"dados de treino: {X_train_transformed.shape}\")\n",
    "# print(f\"dados de teste: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"dados de treino: {X_train.shape}\")\n",
    "print(f\"dados de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(2, 15))\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_pca, y_train_int)\n",
    "    \n",
    "    y_test_int_pred = knn.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test_int, y_test_int_pred)\n",
    "    metrics.append({\n",
    "        'k': k,\n",
    "        'accuracy': test_accuracy,\n",
    "        'classification_report': classification_report(y_test_int, y_test_int_pred, output_dict=True),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = None\n",
    "\n",
    "for metric in metrics:\n",
    "    if best_metric is None or metric['accuracy'] > best_metric['accuracy']:\n",
    "        best_metric = metric\n",
    "\n",
    "\n",
    "if best_metric:\n",
    "    print(f'Best K = {best_metric[\"k\"]}')\n",
    "    k_best = best_metric[\"k\"]\n",
    "    print(f'Best Test Accuracy: {best_metric[\"accuracy\"] * 100:.2f}%')\n",
    "    print('Best Classification Report:')\n",
    "    print(classification_report(y_test_int, knn.predict(X_test_pca)))\n",
    "conf_matrix = confusion_matrix(y_test_int, y_test_int_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title(f'Confusion Matrix for K={k_best}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors=k_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(scaler, knn_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred_initial = svc.predict(X_test_pca)\n",
    "initial_accuracy = accuracy_score(y_test, y_pred_initial)\n",
    "print(f'Acurácia do modelo SVC: {initial_accuracy:.4f}')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_initial)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão - Modelo Inicial')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.ylabel('Classe Real')\n",
    "plt.xlabel('Classe Predita')\n",
    "plt.tight_layout()\n",
    "\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # ('SVM', SVC(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=k_best)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models:\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    end_time = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    recall = classification_rep['weighted avg']['recall']\n",
    "    f1_score = classification_rep['weighted avg']['f1-score']\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia %': round(accuracy * 100, 2),\n",
    "        'Recall %': round(recall * 100, 2),\n",
    "        'F1-score %': round(f1_score * 100, 2),\n",
    "        'Tempo de Execução (s)': round(runtime, 2)\n",
    "    })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df = pd.DataFrame(results)\n",
    "\n",
    "print(resultados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "cont5 = 0\n",
    "\n",
    "for i in range(len(teste)):\n",
    "    if teste[i] == 5:\n",
    "        cont5 +=1\n",
    "    elif teste[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste[i] == 0:\n",
    "        cont0 += 1\n",
    "\n",
    "print(f'Frequências similares a 0: {cont0}')\n",
    "print(f'Frequências similares a 1: {cont1}')\n",
    "print(f'Frequências similares a 2: {cont2}')\n",
    "print(f'Frequências similares a 3: {cont3}')\n",
    "print(f'Frequências similares a 4: {cont4}')\n",
    "print(f'Frequências similares a 5: {cont5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly', 'Dido']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4, cont5]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('moli_assovio_2.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste4 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib.fit(X_train, y_train)\n",
    "teste = knn_from_joblib.predict(teste4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After save:\",knn_from_joblib.predict(teste4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "\n",
    "for i in range(len(teste)):\n",
    "    if teste[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste[i] == 0:\n",
    "        cont0 += 1\n",
    "\n",
    "print(f'Frequências similares a 0: {cont0}')\n",
    "print(f'Frequências similares a 1: {cont1}')\n",
    "print(f'Frequências similares a 2: {cont2}')\n",
    "print(f'Frequências similares a 3: {cont3}')\n",
    "print(f'Frequências similares a 4: {cont4}')\n",
    "\n",
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2_novo = teste2.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib.fit(X_train, y_train)\n",
    "teste = knn_from_joblib.predict(teste2)\n",
    "print(\"After save:\",teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "\n",
    "for i in range(len(teste)):\n",
    "    if teste[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste[i] == 0:\n",
    "        cont0 += 1\n",
    "\n",
    "print(f'Frequências similares a 0: {cont0}')\n",
    "print(f'Frequências similares a 1: {cont1}')\n",
    "print(f'Frequências similares a 2: {cont2}')\n",
    "print(f'Frequências similares a 3: {cont3}')\n",
    "print(f'Frequências similares a 4: {cont4}')\n",
    "\n",
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('tetse.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste7 = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste7.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib.fit(X_train, y_train)\n",
    "teste123 = knn_from_joblib.predict(teste7)\n",
    "print(\"After save:\",teste123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "\n",
    "total = len(teste123)\n",
    "\n",
    "for i in range(total):\n",
    "    if teste123[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste123[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste123[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste123[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste123[i] == 0:\n",
    "        cont0 += 1\n",
    "\n",
    "print(f'Frequências similares a 0: {(cont0 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 1: {(cont1 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 2: {(cont2 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 3: {(cont3 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 4: {(cont4 / total) * 100:.2f}%')\n",
    "\n",
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('eminem.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste_em = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib.fit(X_train, y_train)\n",
    "teste1234 = knn_from_joblib.predict(teste_em)\n",
    "print(\"After save:\",teste1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "cont5 = 0\n",
    "\n",
    "total = len(teste1234)\n",
    "\n",
    "for i in range(len(teste1234)):\n",
    "    if teste1234[i] == 5:\n",
    "        cont5 +=1\n",
    "    elif teste1234[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste1234[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste1234[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste1234[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste1234[i] == 0:\n",
    "        cont0 += 1\n",
    "\n",
    "print(f'Frequências similares a 0: {(cont0 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 1: {(cont1 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 2: {(cont2 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 3: {(cont3 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 4: {(cont4 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 5: {(cont5 / total) * 100:.2f}%')\n",
    "\n",
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly','Dido']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4, cont5]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_hashes = []\n",
    "\n",
    "# https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "\n",
    "y, sr = librosa.load('tim_maia.wav', sr=None, mono=True)\n",
    "Audio(y, rate= sr)\n",
    "\n",
    "S = librosa.stft(y, n_fft=2048, hop_length=512, win_length=1024)\n",
    "S = np.abs(S)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "\n",
    "img = dp.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time', sr=sr)\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "ax2.set_title('Spectrogram')\n",
    "\n",
    "# Encontrar os índices dos valores máximos\n",
    "max_indices = np.argwhere(S == np.max(S, axis=0))\n",
    "\n",
    "# Obter os tempos e as frequências correspondentes\n",
    "times = librosa.frames_to_time(max_indices[:, 1], sr=sr)\n",
    "frequencies = librosa.fft_frequencies(sr=sr)[max_indices[:, 0]]\n",
    "\n",
    "ax2.scatter(times, frequencies, marker='x', color='green', label='Max Values')\n",
    "\n",
    "df_hashes.append(pd.DataFrame({'Frequencia': frequencies, 'Tempo': times}))\n",
    "\n",
    "teste_leans = pd.DataFrame({'Frequencia': frequencies, 'Tempo': times})\n",
    "\n",
    "df_concat = pd.concat(df_hashes, ignore_index=True)\n",
    "print(len(df_concat))\n",
    "freq_2 = frequencies\n",
    "\n",
    "ax1.scatter(df_concat['Tempo'], df_concat['Frequencia'], marker='o')\n",
    "ax1.set_title('Relação entre Frequência e Tempo')\n",
    "ax1.set_ylabel('Hz')\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_from_joblib.fit(X_train, y_train)\n",
    "teste12345 = knn_from_joblib.predict(teste_leans)\n",
    "print(\"After save:\",teste12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont0 = 0\n",
    "cont1 = 0\n",
    "cont2 = 0\n",
    "cont3 = 0\n",
    "cont4 = 0\n",
    "cont5 = 0\n",
    "cont_22 = 0\n",
    "\n",
    "total = len(teste12345)\n",
    "\n",
    "for i in range(len(teste12345)):\n",
    "    if teste12345[i] == 5:\n",
    "        cont5 +=1\n",
    "    elif teste12345[i] == 4:\n",
    "        cont4 += 1       \n",
    "    elif teste12345[i] == 3:\n",
    "        cont3 += 1\n",
    "    elif teste12345[i] == 2:\n",
    "        cont2 += 1\n",
    "    elif teste12345[i] == 1:\n",
    "        cont1 += 1\n",
    "    elif teste12345[i] == 0:\n",
    "        cont0 += 1\n",
    "    else:\n",
    "        cont_22 +=1\n",
    "\n",
    "print(f'Frequências similares a 0: {(cont0 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 1: {(cont1 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 2: {(cont2 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 3: {(cont3 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 4: {(cont4 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 5: {(cont5 / total) * 100:.2f}%')\n",
    "print(f'Frequências similares a 6: {(cont_22 / total) * 100:.2f}%')\n",
    "\n",
    "labels = ['Assovio Matheus', 'Assovio João', 'Assovio Carol', 'Ratos', 'Soulfly','Dido', 'False']\n",
    "frequencies = [cont0, cont1, cont2, cont3, cont4, cont5, cont_22]\n",
    "\n",
    "plt.bar(labels, frequencies, color='blue')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Frequência dos Valores')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
