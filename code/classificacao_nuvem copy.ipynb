{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joao.victor.ribeiro\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joao.victor.ribeiro\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('artists-data.csv')\n",
    "songs = pd.read_csv('lyrics-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = [str(s).split(';') for s in artists['Genres'].unique()]\n",
    "res = list(chain(*genres_list))\n",
    "res = [gen.strip() for gen in res]\n",
    "genres = list(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres:\n",
    "    contains = [True if re.search(genre, str(art_gen)) else False for art_gen in artists['Genres']]\n",
    "    artists[genre] = contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = songs.merge(artists, how='outer', left_on='ALink', right_on='Link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_country = all_songs[all_songs['Country']==False].sample(n=2500, random_state=1)\n",
    "yes_country = all_songs[all_songs['Country']==True].sample(n=2500, random_state=1)\n",
    "no_rock = all_songs[all_songs['Rock']==False].sample(n=2500, random_state=1)\n",
    "yes_rock = all_songs[all_songs['Rock']==True].sample(n=2500, random_state=1)\n",
    "no_rap = all_songs[all_songs['Rap']==False].sample(n=2500, random_state=1)\n",
    "yes_rap = all_songs[all_songs['Rap']==True].sample(n=2500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([no_country, yes_country, no_rock, yes_rock, no_rap, yes_rap]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = all_songs['Lyric'].astype(str)\n",
    "low = [lyr.lower() for lyr in lyrics]\n",
    "tokenized = [word_tokenize(lyr) for lyr in low]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_vec = [[w for w in tok if w not in stop_words] for tok in tokenized]\n",
    "clean_vec = [[word for word in lyr if word.isalpha()] for lyr in stop_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [' '.join(lyr) for lyr in clean_vec]\n",
    "vectorize = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "vectors = vectorize.fit_transform(lyrics)\n",
    "feature_names = vectorize.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "dense_list = dense.tolist()\n",
    "df = pd.DataFrame(dense_list, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = all_songs['Country'].copy()\n",
    "df['Rock'] = all_songs['Rock'].copy()\n",
    "df['Rap'] = all_songs['Rap'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Country', 'Rock', 'Rap']\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Country:\n",
      "Accuracy: 0.8253333333333334\n",
      "Precision: 0.6262626262626263\n",
      "Recall: 0.21602787456445993\n",
      "Confusion Matrix: \n",
      "[[3528  111]\n",
      " [ 675  186]]\n",
      "\n",
      "Results for Rock:\n",
      "Accuracy: 0.7206666666666667\n",
      "Precision: 0.5460434983803795\n",
      "Recall: 0.8104395604395604\n",
      "Confusion Matrix: \n",
      "[[2063  981]\n",
      " [ 276 1180]]\n",
      "\n",
      "Results for Rap:\n",
      "Accuracy: 0.9042222222222223\n",
      "Precision: 0.7940761636107193\n",
      "Recall: 0.6639150943396226\n",
      "Confusion Matrix: \n",
      "[[3506  146]\n",
      " [ 285  563]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    y = df[genre].copy()\n",
    "    x = df.drop(genres, axis=1)  # Remove all genre columns\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "    clf = MultinomialNB(alpha=0.1)\n",
    "    clf.fit(x_train, y_train.astype(bool))\n",
    "    models[genre] = clf\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test.astype(bool), y_pred)\n",
    "    precision = metrics.precision_score(y_test.astype(bool), y_pred)\n",
    "    recall = metrics.recall_score(y_test.astype(bool), y_pred)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test.astype(bool), y_pred)\n",
    "    \n",
    "    print(f\"Results for {genre}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Confusion Matrix: \\n{confusion_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah, I know sometimes\\nThings may not always ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  Yeah, I know sometimes\\nThings may not always ..."
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'lyric.txt'\n",
    "text_content = read_txt_file(file_path)\n",
    "df = pd.DataFrame({'lyrics': [text_content]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'lyric.csv'\n",
    "\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Yeah',\n",
       "  'I',\n",
       "  'know',\n",
       "  'sometimes',\n",
       "  'Things',\n",
       "  'may',\n",
       "  'always',\n",
       "  'make',\n",
       "  'sense',\n",
       "  'right',\n",
       "  'But',\n",
       "  'hey',\n",
       "  'daddy',\n",
       "  'always',\n",
       "  'tell',\n",
       "  'Straighten',\n",
       "  'little',\n",
       "  'soldier',\n",
       "  'Stiffen',\n",
       "  'upper',\n",
       "  'lip',\n",
       "  'What',\n",
       "  'cryin',\n",
       "  'You',\n",
       "  'got',\n",
       "  'Hailie',\n",
       "  'I',\n",
       "  'know',\n",
       "  'miss',\n",
       "  'mom',\n",
       "  'I',\n",
       "  'know',\n",
       "  'miss',\n",
       "  'dad',\n",
       "  'Well',\n",
       "  'I',\n",
       "  'gone',\n",
       "  'I',\n",
       "  'tryin',\n",
       "  'give',\n",
       "  'life',\n",
       "  'I',\n",
       "  'never',\n",
       "  'I',\n",
       "  'see',\n",
       "  'sad',\n",
       "  'even',\n",
       "  'smile',\n",
       "  'even',\n",
       "  'laugh',\n",
       "  'I',\n",
       "  'see',\n",
       "  'eye',\n",
       "  'deep',\n",
       "  'inside',\n",
       "  'want',\n",
       "  'cry',\n",
       "  'scared',\n",
       "  'I',\n",
       "  'ai',\n",
       "  'Daddy',\n",
       "  'prayer',\n",
       "  'No',\n",
       "  'cryin',\n",
       "  'wipe',\n",
       "  'tear',\n",
       "  'Daddy',\n",
       "  'nightmare',\n",
       "  'We',\n",
       "  'gon',\n",
       "  'pull',\n",
       "  'together',\n",
       "  'gon',\n",
       "  'Lainie',\n",
       "  'uncle',\n",
       "  'crazy',\n",
       "  'ai',\n",
       "  'Yeah',\n",
       "  'love',\n",
       "  'girl',\n",
       "  'better',\n",
       "  'know',\n",
       "  'We',\n",
       "  'got',\n",
       "  'world',\n",
       "  'When',\n",
       "  'spin',\n",
       "  'swirl',\n",
       "  'When',\n",
       "  'whirl',\n",
       "  'twirl',\n",
       "  'Two',\n",
       "  'little',\n",
       "  'beautiful',\n",
       "  'girl',\n",
       "  'Lookin',\n",
       "  'puzzled',\n",
       "  'daze',\n",
       "  'I',\n",
       "  'know',\n",
       "  'confusin',\n",
       "  'Daddy',\n",
       "  'always',\n",
       "  'move',\n",
       "  'mama',\n",
       "  'always',\n",
       "  'news',\n",
       "  'I',\n",
       "  'try',\n",
       "  'keep',\n",
       "  'sheltered',\n",
       "  'somehow',\n",
       "  'seems',\n",
       "  'The',\n",
       "  'harder',\n",
       "  'I',\n",
       "  'try',\n",
       "  'backfire',\n",
       "  'All',\n",
       "  'thing',\n",
       "  'growin',\n",
       "  'daddy',\n",
       "  'see',\n",
       "  'Daddy',\n",
       "  'want',\n",
       "  'see',\n",
       "  'see',\n",
       "  'much',\n",
       "  'We',\n",
       "  'plan',\n",
       "  'way',\n",
       "  'mother',\n",
       "  'But',\n",
       "  'thing',\n",
       "  'gotten',\n",
       "  'bad',\n",
       "  'u',\n",
       "  'I',\n",
       "  'see',\n",
       "  'u',\n",
       "  'ever',\n",
       "  'bein',\n",
       "  'together',\n",
       "  'ever',\n",
       "  'Like',\n",
       "  'used',\n",
       "  'teenager',\n",
       "  'But',\n",
       "  'course',\n",
       "  'everything',\n",
       "  'always',\n",
       "  'happens',\n",
       "  'reason',\n",
       "  'I',\n",
       "  'guess',\n",
       "  'never',\n",
       "  'meant',\n",
       "  'But',\n",
       "  'something',\n",
       "  'control',\n",
       "  'destiny',\n",
       "  'But',\n",
       "  'worry',\n",
       "  'rest',\n",
       "  'head',\n",
       "  'go',\n",
       "  'sleep',\n",
       "  'Maybe',\n",
       "  'one',\n",
       "  'day',\n",
       "  'wake',\n",
       "  'dream',\n",
       "  'Now',\n",
       "  'hush',\n",
       "  'little',\n",
       "  'baby',\n",
       "  'cry',\n",
       "  'Everything',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'alright',\n",
       "  'Stiffen',\n",
       "  'upper',\n",
       "  'lip',\n",
       "  'little',\n",
       "  'lady',\n",
       "  'I',\n",
       "  'told',\n",
       "  'ya',\n",
       "  'Daddy',\n",
       "  'hold',\n",
       "  'ya',\n",
       "  'night',\n",
       "  'I',\n",
       "  'know',\n",
       "  'mommy',\n",
       "  'right',\n",
       "  'know',\n",
       "  'We',\n",
       "  'feel',\n",
       "  'feel',\n",
       "  'inside',\n",
       "  'It',\n",
       "  'may',\n",
       "  'seem',\n",
       "  'little',\n",
       "  'crazy',\n",
       "  'pretty',\n",
       "  'baby',\n",
       "  'But',\n",
       "  'I',\n",
       "  'promise',\n",
       "  'mama',\n",
       "  'gon',\n",
       "  'alright',\n",
       "  'It',\n",
       "  'funny',\n",
       "  'I',\n",
       "  'remember',\n",
       "  'back',\n",
       "  'one',\n",
       "  'year',\n",
       "  'daddy',\n",
       "  'money',\n",
       "  'Mommy',\n",
       "  'wrapped',\n",
       "  'Christmas',\n",
       "  'present',\n",
       "  'And',\n",
       "  'stuck',\n",
       "  'tree',\n",
       "  'said',\n",
       "  'daddy',\n",
       "  'could',\n",
       "  'buy',\n",
       "  'I',\n",
       "  'never',\n",
       "  'forget',\n",
       "  'Christmas',\n",
       "  'I',\n",
       "  'sat',\n",
       "  'whole',\n",
       "  'night',\n",
       "  'cry',\n",
       "  'daddy',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'bum',\n",
       "  'see',\n",
       "  'daddy',\n",
       "  'job',\n",
       "  'But',\n",
       "  'job',\n",
       "  'keep',\n",
       "  'food',\n",
       "  'table',\n",
       "  'mom',\n",
       "  'And',\n",
       "  'time',\n",
       "  'every',\n",
       "  'house',\n",
       "  'lived',\n",
       "  'Either',\n",
       "  'kept',\n",
       "  'gettin',\n",
       "  'broke',\n",
       "  'robbed',\n",
       "  'shot',\n",
       "  'block',\n",
       "  'And',\n",
       "  'mom',\n",
       "  'savin',\n",
       "  'money',\n",
       "  'jar',\n",
       "  'Tryna',\n",
       "  'start',\n",
       "  'piggy',\n",
       "  'bank',\n",
       "  'could',\n",
       "  'go',\n",
       "  'college',\n",
       "  'Almost',\n",
       "  'thousand',\n",
       "  'dollar',\n",
       "  'till',\n",
       "  'someone',\n",
       "  'broke',\n",
       "  'stole',\n",
       "  'And',\n",
       "  'I',\n",
       "  'know',\n",
       "  'hurt',\n",
       "  'bad',\n",
       "  'broke',\n",
       "  'mama',\n",
       "  'heart',\n",
       "  'And',\n",
       "  'seemed',\n",
       "  'like',\n",
       "  'everything',\n",
       "  'startin',\n",
       "  'fall',\n",
       "  'apart',\n",
       "  'Mom',\n",
       "  'dad',\n",
       "  'arguin',\n",
       "  'lot',\n",
       "  'momma',\n",
       "  'moved',\n",
       "  'back',\n",
       "  'On',\n",
       "  'Chalmers',\n",
       "  'flat',\n",
       "  'apartment',\n",
       "  'And',\n",
       "  'dad',\n",
       "  'moved',\n",
       "  'back',\n",
       "  'side',\n",
       "  'Mile',\n",
       "  'Novara',\n",
       "  'And',\n",
       "  'daddy',\n",
       "  'went',\n",
       "  'California',\n",
       "  'CD',\n",
       "  'met',\n",
       "  'Dre',\n",
       "  'And',\n",
       "  'flew',\n",
       "  'momma',\n",
       "  'see',\n",
       "  'But',\n",
       "  'daddy',\n",
       "  'work',\n",
       "  'momma',\n",
       "  'leave',\n",
       "  'Then',\n",
       "  'started',\n",
       "  'seein',\n",
       "  'daddy',\n",
       "  'TV',\n",
       "  'momma',\n",
       "  'like',\n",
       "  'And',\n",
       "  'Lainie',\n",
       "  'young',\n",
       "  'understand',\n",
       "  'Papa',\n",
       "  'rolling',\n",
       "  'stone',\n",
       "  'momma',\n",
       "  'developed',\n",
       "  'habit',\n",
       "  'And',\n",
       "  'happened',\n",
       "  'fast',\n",
       "  'either',\n",
       "  'one',\n",
       "  'u',\n",
       "  'grab',\n",
       "  'I',\n",
       "  'sorry',\n",
       "  'witness',\n",
       "  'first',\n",
       "  'hand',\n",
       "  'I',\n",
       "  'ever',\n",
       "  'wanted',\n",
       "  'make',\n",
       "  'proud',\n",
       "  'Now',\n",
       "  'I',\n",
       "  'sittin',\n",
       "  'empty',\n",
       "  'house',\n",
       "  'Lookin',\n",
       "  'baby',\n",
       "  'picture',\n",
       "  'trip',\n",
       "  'To',\n",
       "  'see',\n",
       "  'much',\n",
       "  'grown',\n",
       "  'almost',\n",
       "  'like',\n",
       "  'sister',\n",
       "  'Wow',\n",
       "  'guess',\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'daddy',\n",
       "  'still',\n",
       "  'Lainie',\n",
       "  'I',\n",
       "  'talkin',\n",
       "  'daddy',\n",
       "  'still',\n",
       "  'I',\n",
       "  'like',\n",
       "  'sound',\n",
       "  'yeah',\n",
       "  'It',\n",
       "  'got',\n",
       "  'ring',\n",
       "  'Shh',\n",
       "  'mama',\n",
       "  'gone',\n",
       "  'moment',\n",
       "  'Now',\n",
       "  'hush',\n",
       "  'little',\n",
       "  'baby',\n",
       "  'cry',\n",
       "  'Everything',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'alright',\n",
       "  'Stiffen',\n",
       "  'upper',\n",
       "  'lip',\n",
       "  'little',\n",
       "  'lady',\n",
       "  'I',\n",
       "  'told',\n",
       "  'ya',\n",
       "  'Daddy',\n",
       "  'hold',\n",
       "  'ya',\n",
       "  'night',\n",
       "  'I',\n",
       "  'know',\n",
       "  'mommy',\n",
       "  'right',\n",
       "  'know',\n",
       "  'We',\n",
       "  'feel',\n",
       "  'feel',\n",
       "  'inside',\n",
       "  'It',\n",
       "  'may',\n",
       "  'seem',\n",
       "  'little',\n",
       "  'crazy',\n",
       "  'pretty',\n",
       "  'baby',\n",
       "  'But',\n",
       "  'I',\n",
       "  'promise',\n",
       "  'mama',\n",
       "  'gon',\n",
       "  'alright',\n",
       "  'And',\n",
       "  'ask',\n",
       "  'Daddy',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'buy',\n",
       "  'mockingbird',\n",
       "  'give',\n",
       "  'world',\n",
       "  'buy',\n",
       "  'diamond',\n",
       "  'ring',\n",
       "  'sing',\n",
       "  'I',\n",
       "  'anything',\n",
       "  'see',\n",
       "  'smile',\n",
       "  'And',\n",
       "  'mocking',\n",
       "  'bird',\n",
       "  'sing',\n",
       "  'ring',\n",
       "  'shine',\n",
       "  'break',\n",
       "  'birdie',\n",
       "  'neck',\n",
       "  'I',\n",
       "  'go',\n",
       "  'back',\n",
       "  'jeweler',\n",
       "  'sold',\n",
       "  'ya',\n",
       "  'And',\n",
       "  'make',\n",
       "  'eat',\n",
       "  'every',\n",
       "  'carat',\n",
       "  'fuck',\n",
       "  'dad',\n",
       "  'haha']]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tay = pd.read_csv('lyric.csv', encoding='latin1')\n",
    "tay.columns\n",
    "teste = tay['lyrics']\n",
    "tokenized = [word_tokenize(lyr) for lyr in teste.astype(str)]\n",
    "stop_vec = [[w for w in tok if w not in stop_words] for tok in tokenized]\n",
    "clean_vec = [[word for word in lyr if word.isalpha()] for lyr in stop_vec]\n",
    "wnet = nltk.WordNetLemmatizer()\n",
    "lem = [[wnet.lemmatize(w) for w in lyr] for lyr in clean_vec]\n",
    "\n",
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yeah I know sometimes Things may always make sense right But hey daddy always tell Straighten little soldier Stiffen upper lip What cryin You got Hailie I know miss mom I know miss dad Well I gone I tryin give life I never I see sad even smile even laugh I see eye deep inside want cry scared I ai Daddy prayer No cryin wipe tear Daddy nightmare We gon pull together gon Lainie uncle crazy ai Yeah love girl better know We got world When spin swirl When whirl twirl Two little beautiful girl Lookin puzzled daze I know confusin Daddy always move mama always news I try keep sheltered somehow seems The harder I try backfire All thing growin daddy see Daddy want see see much We plan way mother But thing gotten bad u I see u ever bein together ever Like used teenager But course everything always happens reason I guess never meant But something control destiny But worry rest head go sleep Maybe one day wake dream Now hush little baby cry Everything gon na alright Stiffen upper lip little lady I told ya Daddy hold ya night I know mommy right know We feel feel inside It may seem little crazy pretty baby But I promise mama gon alright It funny I remember back one year daddy money Mommy wrapped Christmas present And stuck tree said daddy could buy I never forget Christmas I sat whole night cry daddy felt like bum see daddy job But job keep food table mom And time every house lived Either kept gettin broke robbed shot block And mom savin money jar Tryna start piggy bank could go college Almost thousand dollar till someone broke stole And I know hurt bad broke mama heart And seemed like everything startin fall apart Mom dad arguin lot momma moved back On Chalmers flat apartment And dad moved back side Mile Novara And daddy went California CD met Dre And flew momma see But daddy work momma leave Then started seein daddy TV momma like And Lainie young understand Papa rolling stone momma developed habit And happened fast either one u grab I sorry witness first hand I ever wanted make proud Now I sittin empty house Lookin baby picture trip To see much grown almost like sister Wow guess pretty much daddy still Lainie I talkin daddy still I like sound yeah It got ring Shh mama gone moment Now hush little baby cry Everything gon na alright Stiffen upper lip little lady I told ya Daddy hold ya night I know mommy right know We feel feel inside It may seem little crazy pretty baby But I promise mama gon alright And ask Daddy gon na buy mockingbird give world buy diamond ring sing I anything see smile And mocking bird sing ring shine break birdie neck I go back jeweler sold ya And make eat every carat fuck dad haha']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_tay = [' '.join(lyr) for lyr in lem]\n",
    "single_entry = vectorize.transform(lyrics_tay)\n",
    "s_e = single_entry.todense().tolist()\n",
    "\n",
    "lyrics_tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = {genre: clf.predict(s_e) for genre in genres}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: 17.88%\n",
      "Rock: 93.86%\n",
      "Rap: 66.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "probabilities = {genre: models[genre].predict_proba(s_e)[0][1] for genre in genres}\n",
    "\n",
    "for genre, prob in probabilities.items():\n",
    "    print(f\"{genre}: {prob * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
